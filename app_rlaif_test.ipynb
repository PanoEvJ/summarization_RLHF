{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix6Sc4hVIkS5"
      },
      "source": [
        "# Reinforcement Learning from AI Feedback (RLAIF)\n",
        "\n",
        "## Enhancing T5-Base Summarization with Proximal Policy Optimization (PPO) and PEFT Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ee-7XQrPIkS-"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch\n",
        "!pip install -q transformers\n",
        "!pip install -q datasets\n",
        "!pip install -q trl\n",
        "!pip install -q peft\n",
        "!pip install -q numpy\n",
        "!pip install -q pandas\n",
        "!pip install -q tqdm\n",
        "!pip install -q openai\n",
        "!pip install -q wandb\n",
        "!pip install -U -q sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YE2XRxq2IkTB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset as TorchDataset\n",
        "from torch.optim import AdamW\n",
        "\n",
        "from datasets import load_dataset, Dataset as HFDataset\n",
        "\n",
        "from peft import PeftModel, PeftConfig,  TaskType\n",
        "\n",
        "from peft import (\n",
        "    get_peft_config,\n",
        "    get_peft_model,\n",
        "    get_peft_model_state_dict,\n",
        "    set_peft_model_state_dict,\n",
        "    PeftType,\n",
        "    LoraConfig,\n",
        ")\n",
        "\n",
        "# AutoModelForCausalLMWithValueHead & AutoModelForSeq2SeqLMWithValueHead: A transformer model with an additional scalar output for each token which can be used as a value function in reinforcement learning.\n",
        "# https://huggingface.co/docs/trl/models#trl.AutoModelForSeq2SeqLMWithValueHead\n",
        "\n",
        "# trl: Transformer Reinforcement Learning library\n",
        "import trl\n",
        "from trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead # https://huggingface.co/docs/trl/quickstart\n",
        "from trl import create_reference_model\n",
        "from trl.core import LengthSampler\n",
        "\n",
        "# import evaluate\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# tqdm library makes the loops show a smart progress meter.\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bvWvCQ2nIkTC"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VcYx683EOioM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16dd0a54-97bd-49a0-d6b1-66688a038bb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "openai_api_key = getpass.getpass(\"Enter your OpenAI API Key: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "# 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"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TjNaIdoVa9nq"
      },
      "outputs": [],
      "source": [
        "orig_dataset = load_dataset('CarperAI/openai_summarize_comparisons', split='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4zTrDq6nbXih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b88b84c-39f6-42e0-b59c-7c13486a93c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prompt': \"SUBREDDIT: r/AskReddit\\nTITLE: Recommendations for I/O Psychology Graduate Programs?\\nPOST: I'm in junior standing right now where I'm supposed to figure out what I need to do with my life (grad school vs full-time job) and so I intended to go to grad school for a Masters and be done with school forever.  The thing is I don't know what schools are truly good and worth their money for I/O programs.  I've already crossed-searched to narrow it down to these and could narrow it further: CSU Long Beach, CSU San Bernardino, CSU San Francisco, San Jose State, San Diego State, Chapman University, and Claremont Graduate University.  Yes? No? I should just travel back in time and start over?\\n\\nI am firm about staying in California for grad studies and if I/O doesn't work out, maybe MBA might?  I would only stick around for my 4th year to buy time with getting research, internships, and minor in business administration.  Would it even work out if I get a really good GMAT score with a minor in business administration?\",\n",
              " 'chosen': \"TL;DR:  Considering grad school to get a Masters in I/O Psychology, doesn't know where to get good schools in California and/or what programs to look into.  Any advice is appreciated.\",\n",
              " 'rejected': 'TL;DR:  I/O Psychology, is there anything worth going to school for? Also, if not, what are some good schools that I should look into for MBA?'}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "orig_dataset[10000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5gETCZqOfKU"
      },
      "source": [
        "# RLHF Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "aRnt__ajIkTF"
      },
      "outputs": [],
      "source": [
        "policy_model_path = \"JuanKO/rlhf_base_model\"\n",
        "policy_model_name = \"t5-base\"\n",
        "\n",
        "policy_model = T5ForConditionalGeneration.from_pretrained(policy_model_path)\n",
        "policy_model.to(device)\n",
        "policy_tokenizer = T5Tokenizer.from_pretrained(policy_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "jtiqUbdPIkTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26b16546-5c44-44b5-e580-27d55e9df306"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForSeq2SeqLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): T5ForConditionalGeneration(\n",
              "      (shared): Embedding(32128, 768)\n",
              "      (encoder): T5Stack(\n",
              "        (embed_tokens): Embedding(32128, 768)\n",
              "        (block): ModuleList(\n",
              "          (0): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (relative_attention_bias): Embedding(32, 12)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1-11): 11 x T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_layer_norm): T5LayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (decoder): T5Stack(\n",
              "        (embed_tokens): Embedding(32128, 768)\n",
              "        (block): ModuleList(\n",
              "          (0): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (relative_attention_bias): Embedding(32, 12)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1-11): 11 x T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_layer_norm): T5LayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=8, # Rank\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.10,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM # T5\n",
        ")\n",
        "\n",
        "policy_peft_model = get_peft_model(policy_model, lora_config)\n",
        "policy_peft_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Z_SFOc-1IkTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4e4b2e2-c205-418e-d9a0-dbdccf789530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 884,736 || all params: 223,788,288 || trainable%: 0.3953450861557152\n"
          ]
        }
      ],
      "source": [
        "policy_peft_model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "txdIgFSkIkTI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b795ef5d-cadf-4a2e-c221-4c368d347553"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AutoModelForSeq2SeqLMWithValueHead(\n",
              "  (pretrained_model): PeftModelForSeq2SeqLM(\n",
              "    (base_model): LoraModel(\n",
              "      (model): T5ForConditionalGeneration(\n",
              "        (shared): Embedding(32128, 768)\n",
              "        (encoder): T5Stack(\n",
              "          (embed_tokens): Embedding(32128, 768)\n",
              "          (block): ModuleList(\n",
              "            (0): T5Block(\n",
              "              (layer): ModuleList(\n",
              "                (0): T5LayerSelfAttention(\n",
              "                  (SelfAttention): T5Attention(\n",
              "                    (q): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (v): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (relative_attention_bias): Embedding(32, 12)\n",
              "                  )\n",
              "                  (layer_norm): T5LayerNorm()\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (1): T5LayerFF(\n",
              "                  (DenseReluDense): T5DenseActDense(\n",
              "                    (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                    (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                    (dropout): Dropout(p=0.1, inplace=False)\n",
              "                    (act): ReLU()\n",
              "                  )\n",
              "                  (layer_norm): T5LayerNorm()\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (1-11): 11 x T5Block(\n",
              "              (layer): ModuleList(\n",
              "                (0): T5LayerSelfAttention(\n",
              "                  (SelfAttention): T5Attention(\n",
              "                    (q): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (v): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  )\n",
              "                  (layer_norm): T5LayerNorm()\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (1): T5LayerFF(\n",
              "                  (DenseReluDense): T5DenseActDense(\n",
              "                    (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                    (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                    (dropout): Dropout(p=0.1, inplace=False)\n",
              "                    (act): ReLU()\n",
              "                  )\n",
              "                  (layer_norm): T5LayerNorm()\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (final_layer_norm): T5LayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (decoder): T5Stack(\n",
              "          (embed_tokens): Embedding(32128, 768)\n",
              "          (block): ModuleList(\n",
              "            (0): T5Block(\n",
              "              (layer): ModuleList(\n",
              "                (0): T5LayerSelfAttention(\n",
              "                  (SelfAttention): T5Attention(\n",
              "                    (q): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (v): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (relative_attention_bias): Embedding(32, 12)\n",
              "                  )\n",
              "                  (layer_norm): T5LayerNorm()\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (1): T5LayerCrossAttention(\n",
              "                  (EncDecAttention): T5Attention(\n",
              "                    (q): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (v): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  )\n",
              "                  (layer_norm): T5LayerNorm()\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (2): T5LayerFF(\n",
              "                  (DenseReluDense): T5DenseActDense(\n",
              "                    (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                    (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                    (dropout): Dropout(p=0.1, inplace=False)\n",
              "                    (act): ReLU()\n",
              "                  )\n",
              "                  (layer_norm): T5LayerNorm()\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (1-11): 11 x T5Block(\n",
              "              (layer): ModuleList(\n",
              "                (0): T5LayerSelfAttention(\n",
              "                  (SelfAttention): T5Attention(\n",
              "                    (q): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (v): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  )\n",
              "                  (layer_norm): T5LayerNorm()\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (1): T5LayerCrossAttention(\n",
              "                  (EncDecAttention): T5Attention(\n",
              "                    (q): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (v): Linear(\n",
              "                      in_features=768, out_features=768, bias=False\n",
              "                      (lora_dropout): ModuleDict(\n",
              "                        (default): Dropout(p=0.1, inplace=False)\n",
              "                      )\n",
              "                      (lora_A): ModuleDict(\n",
              "                        (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                      )\n",
              "                      (lora_B): ModuleDict(\n",
              "                        (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                      )\n",
              "                      (lora_embedding_A): ParameterDict()\n",
              "                      (lora_embedding_B): ParameterDict()\n",
              "                    )\n",
              "                    (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  )\n",
              "                  (layer_norm): T5LayerNorm()\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (2): T5LayerFF(\n",
              "                  (DenseReluDense): T5DenseActDense(\n",
              "                    (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                    (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                    (dropout): Dropout(p=0.1, inplace=False)\n",
              "                    (act): ReLU()\n",
              "                  )\n",
              "                  (layer_norm): T5LayerNorm()\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (final_layer_norm): T5LayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (v_head): ValueHead(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (summary): Linear(in_features=768, out_features=1, bias=True)\n",
              "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# https://huggingface.co/docs/trl/quickstart\n",
        "ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(policy_peft_model,\n",
        "                                                               torch_dtype=torch.bfloat16,\n",
        "                                                               is_trainable=True)\n",
        "\n",
        "ppo_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Jl2ukCSBIkTI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ff0272e-0bc3-497f-d86c-e4941e1030e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 768)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(\n",
              "                in_features=768, out_features=768, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "ref_model = create_reference_model(policy_model)\n",
        "ref_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hioROxkQIkTJ"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "orig_dataset = load_dataset('CarperAI/openai_summarize_comparisons', split='test')\n",
        "\n",
        "# Filter samples where the prompt length is less than or equal to 750\n",
        "filtered_dataset = orig_dataset.filter(lambda example: len(example['prompt'].split()) <= 450) # By word\n",
        "#filtered_dataset = orig_dataset.filter(lambda example: len(example['prompt']) <= 1250) # By character\n",
        "\n",
        "# Shuffle and select the first 10K samples\n",
        "#shuffled_dataset = orig_dataset.shuffle(seed=42).select(range(1000))\n",
        "shuffled_dataset = filtered_dataset.shuffle(seed=42).select(range(2000))\n",
        "\n",
        "\n",
        "# Extract the desired features.  Renaming chose to response to follow the ppo library requirements.\n",
        "new_dataset_dict = {\n",
        "    \"prompt\": shuffled_dataset[\"prompt\"],\n",
        "    \"response\": shuffled_dataset[\"chosen\"]\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a new Dataset\n",
        "dataset = HFDataset.from_dict(new_dataset_dict)\n",
        "\n",
        "# Split the new_dataset into train_dataset and eval_dataset\n",
        "split_ratio = 0.8  # 80% for training, 20% for evaluation\n",
        "num_train_samples = int(split_ratio * len(dataset))\n",
        "train_dataset = dataset.select(range(num_train_samples))\n",
        "eval_dataset = dataset.select(range(num_train_samples, len(dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Rb-EWoFfIkTJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f35f9b6-9721-45d4-e129-3e5b94dca7a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['prompt', 'response'])\n",
            "dict_keys(['prompt', 'response'])\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset[0].keys())\n",
        "print(eval_dataset[0].keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "i5xBh6z9IkTP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "8587deb801b347ed98ae19c4ad16369a",
            "46ab0db4b0de4fbf9eb5799bef9642c1",
            "6fb10ae4ae6140dc92e104e4d837cfed",
            "ea3903adc01a495aae5435ca07437577",
            "044729feea174714a3b3497701945e99",
            "d39bfcd50ede48ed99bc41c7c8e603ff",
            "07b0f2011f5649d486e383f45def31e3",
            "5449da55e8a140ccac87fd5d29bac9f1",
            "5926eca80cfd43b2aaf346f029a282b9",
            "af2a710ac70a4716b42a1aab62adc7a9",
            "5fed99536689424da956065fbae30bce",
            "c67d4971ca6540389ff0cb4a980f8532",
            "18de551832c54fcda6d13077d9a2de2d",
            "fec60bfc971c4b56bb101f24faf3509e",
            "fe6bfa77fb8d43dba2cb80a82f2d98e9",
            "e3d08ac14f0b413daeaac5c5de257a79",
            "476e4b3e74c046e9bde09ae237624dc5",
            "7ef39464cc5a482f90d1adf398ac8dcc",
            "853eecbaa8be4c79a6a48c7dd85f18ae",
            "1f13c0840a4b48a5a57e5f4a066a16c4",
            "5c4573002747418cb78fa1ace8d35786",
            "6e3428ab10b3424d803140e1ab080965"
          ]
        },
        "outputId": "0f05557a-e78b-4c4e-a984-2a94d5448193"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8587deb801b347ed98ae19c4ad16369a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c67d4971ca6540389ff0cb4a980f8532"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import T5Tokenizer\n",
        "\n",
        "# Instantiate your tokenizer (replace T5Tokenizer with your model's tokenizer if different)\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\") # or whatever model you're using\n",
        "\n",
        "def tokenize_function(example):\n",
        "    # Tokenize the prompt and store it as input_ids. Also return the response.\n",
        "    return {\n",
        "        \"input_ids\": tokenizer(example[\"prompt\"], return_tensors=\"pt\", truncation=True, max_length=1024)[\"input_ids\"].squeeze(),\n",
        "        \"response\": example[\"response\"],\n",
        "    }\n",
        "\n",
        "# Tokenize the training and evaluation datasets\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=False)\n",
        "eval_dataset = eval_dataset.map(tokenize_function, batched=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "NTx08dafIkTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "387509b9-4fbb-47df-ee7b-c69287edb2f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'prompt': \"SUBREDDIT: r/relationship_advice\\nTITLE: [20/m] My girlfriend [20/f] has become very distant and weird\\nPOST: I have been in a relationship with my girlfriend for a little bit over 1 year. We recently had a breakup because I was distant and she thought I was cheating on her (which I wasn't). Before the breakup, she wanted to spend as much time with me as she could, but recently she has been very distant. We used to go to eachothers places overnight almost daily, but nowadays she does not want to come over to my place or want me to go over to hers (We both live on our own). She also used to talk to me all the time on facebook, but now she pretty much only replies to what I talk, and does not try to keep the conversation going. She has became pretty slow at replying, but when I'm with her, she replies instantly to her other friends who text her. \\n\\nI'm really lost at this situation, because I feel like she does not want to be with me anymore. I know that she's taking SSRI medications at the moment for anxiety. But she was taking them before we broke up for couple weeks. Her explanation for this situation is that she wants to spend some time alone, because she is working so much and never has time to be alone. This bothers me because she used to want to be with me all the time she could, and now she does not even try to schedule time for me.\", 'response': 'TL;DR:  gf has became very distant after we got back together, even though before we  broke up she was really into me.', 'input_ids': [3, 4138, 25582, 11253, 3177, 10, 3, 52, 87, 60, 6105, 2009, 834, 9, 26, 7287, 15, 332, 3177, 3765, 10, 784, 1755, 87, 51, 908, 499, 17442, 784, 1755, 87, 89, 908, 65, 582, 182, 10382, 11, 10088, 276, 14464, 10, 27, 43, 118, 16, 3, 9, 1675, 28, 82, 17442, 21, 3, 9, 385, 720, 147, 209, 215, 5, 101, 1310, 141, 3, 9, 1733, 413, 250, 27, 47, 10382, 11, 255, 816, 27, 47, 15009, 53, 30, 160, 41, 3339, 27, 2088, 31, 17, 137, 3103, 8, 1733, 413, 6, 255, 1114, 12, 1492, 38, 231, 97, 28, 140, 38, 255, 228, 6, 68, 1310, 255, 65, 118, 182, 10382, 5, 101, 261, 12, 281, 12, 284, 9269, 7, 1747, 8521, 966, 1444, 6, 68, 18811, 255, 405, 59, 241, 12, 369, 147, 12, 82, 286, 42, 241, 140, 12, 281, 147, 12, 160, 7, 41, 1326, 321, 619, 30, 69, 293, 137, 451, 92, 261, 12, 1350, 12, 140, 66, 8, 97, 30, 13301, 6, 68, 230, 255, 1134, 231, 163, 26719, 12, 125, 27, 1350, 6, 11, 405, 59, 653, 12, 453, 8, 3634, 352, 5, 451, 65, 1632, 1134, 2684, 44, 8776, 53, 6, 68, 116, 27, 31, 51, 28, 160, 6, 255, 26719, 8361, 12, 160, 119, 803, 113, 1499, 160, 5, 27, 31, 51, 310, 1513, 44, 48, 1419, 6, 250, 27, 473, 114, 255, 405, 59, 241, 12, 36, 28, 140, 7595, 5, 27, 214, 24, 255, 31, 7, 838, 3, 4256, 5593, 11208, 44, 8, 798, 21, 6261, 5, 299, 255, 47, 838, 135, 274, 62, 8238, 95, 21, 1158, 1274, 5, 1347, 7295, 21, 48, 1419, 19, 24, 255, 2746, 12, 1492, 128, 97, 2238, 6, 250, 255, 19, 464, 78, 231, 11, 470, 65, 97, 12, 36, 2238, 5, 100, 13965, 7, 140, 250, 255, 261, 12, 241, 12, 36, 28, 140, 66, 8, 97, 255, 228, 6, 11, 230, 255, 405, 59, 237, 653, 12, 2023, 97, 21, 140, 5, 1]}\n"
          ]
        }
      ],
      "source": [
        "# Lets check one sample of the train_dataset\n",
        "print(train_dataset[0])  # print the first example from the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "dBf3f5PkIkTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "165ced5c-1d1d-414a-8626-3a7589ed6980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collator input: [{'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}, {'key1': 'value4', 'key2': 'value5', 'key3': 'value6'}]\n",
            "Collator output: {'key1': ['value1', 'value4'], 'key2': ['value2', 'value5'], 'key3': ['value3', 'value6']}\n",
            "dict_keys(['prompt', 'response', 'input_ids'])\n"
          ]
        }
      ],
      "source": [
        "def collator(data):\n",
        "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
        "\n",
        "test_data = [{\"key1\": \"value1\", \"key2\": \"value2\", \"key3\": \"value3\"}, {\"key1\": \"value4\", \"key2\": \"value5\", \"key3\": \"value6\"}]\n",
        "print(f'Collator input: {test_data}')\n",
        "print(f'Collator output: {collator(test_data)}')\n",
        "\n",
        "# Lets sample what the collator generates:\n",
        "sample_data = [train_dataset[i] for i in range(3)]  # take first three examples\n",
        "collated_data = collator(sample_data)\n",
        "print(collated_data.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "wJxRBHLl7L9R"
      },
      "outputs": [],
      "source": [
        "learning_rate=1e-4\n",
        "max_ppo_epochs=5\n",
        "mini_batch_size=2\n",
        "batch_size=8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "iTi-YYjlIkTR"
      },
      "outputs": [],
      "source": [
        "# Check out https://huggingface.co/docs/trl/trainer\n",
        "\n",
        "config = PPOConfig(\n",
        "    model_name=policy_model_name,\n",
        "    learning_rate=learning_rate,\n",
        "    ppo_epochs=max_ppo_epochs,\n",
        "    mini_batch_size=mini_batch_size,\n",
        "    batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "pfL_CqlTIkTR"
      },
      "outputs": [],
      "source": [
        "# Check out https://huggingface.co/docs/trl/trainer\n",
        "\n",
        "ppo_trainer = PPOTrainer(config=config,\n",
        "                         model=ppo_model,\n",
        "                         ref_model=ref_model,\n",
        "                         tokenizer=policy_tokenizer,\n",
        "                         dataset=train_dataset,\n",
        "                         data_collator=collator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "4VTGWfXg7ekw"
      },
      "outputs": [],
      "source": [
        "# Some initial values\n",
        "output_min_length = 128\n",
        "output_max_length = 2048\n",
        "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
        "\n",
        "# These hyperparams guide the generation of the completion in the policy model. We could add other params like temperature.\n",
        "generation_kwargs = {\n",
        "    \"temperature\": 0.5,\n",
        "    \"min_length\": 5,\n",
        "    \"top_k\": 0.0,\n",
        "    \"top_p\": 1.0,\n",
        "    \"do_sample\": True\n",
        "}\n",
        "\n",
        "max_ppo_steps = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "OkZ3fJM8CPnW"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import re\n",
        "\n",
        "def score_summaries(full_text, summarized_text):\n",
        "\n",
        "  score = 0\n",
        "\n",
        "  try:\n",
        "    prompt = f\"\"\"### FULL TEXT:\\n {full_text} \\n\n",
        "    ### SUMMARIZED TEXT: \\n {summarized_text}\"\"\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        temperature = 0.,\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"system\", \"content\": f\"\"\"You are an expert in text summarization. Below, you are given the full text and its summarization.\n",
        "    Your role is to rate the provided summarization with scores ranging from 0 to 1, where: 0 is the lowest score, 1 is the highest score.\n",
        "    Your response should only be a double precision number that represents the scoring rate.\n",
        "    \"\"\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}],\n",
        "        request_timeout=60000\n",
        "    )\n",
        "    response = response['choices'][0]['message']['content']\n",
        "    score    = float(re.findall(r\"[-+]?(?:\\d*\\.*\\d+)\", response)[0])\n",
        "  except:\n",
        "    score = 0.5\n",
        "\n",
        "  return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "9KrKa3f7xNZL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "1285b21d-c1d3-4cc8-f8a1-d29a83ce6ecb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"SUBREDDIT: r/AskReddit\\nTITLE: Recommendations for I/O Psychology Graduate Programs?\\nPOST: I'm in junior standing right now where I'm supposed to figure out what I need to do with my life (grad school vs full-time job) and so I intended to go to grad school for a Masters and be done with school forever.  The thing is I don't know what schools are truly good and worth their money for I/O programs.  I've already crossed-searched to narrow it down to these and could narrow it further: CSU Long Beach, CSU San Bernardino, CSU San Francisco, San Jose State, San Diego State, Chapman University, and Claremont Graduate University.  Yes? No? I should just travel back in time and start over?\\n\\nI am firm about staying in California for grad studies and if I/O doesn't work out, maybe MBA might?  I would only stick around for my 4th year to buy time with getting research, internships, and minor in business administration.  Would it even work out if I get a really good GMAT score with a minor in business administration?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "orig_dataset[10000]['prompt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "YOFkiLmUIkTS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d7f69ac8-9b54-47f7-dec0-3e74762914b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-dfa417f09ad2>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  prompt_tensor = torch.tensor(prompt_tensor).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 0.0\n",
            "ppo/returns/mean: 0.41591235995292664\n",
            "ppo/policy/advantages_mean: 0.030293894931674004\n",
            "STEP: 0\n",
            "---------------------------------------------------------------------------------------------------\n",
            "objective/kl: 0.28584426641464233\n",
            "ppo/returns/mean: 0.4443729519844055\n",
            "ppo/policy/advantages_mean: 0.0017045646673068404\n",
            "STEP: 1\n",
            "---------------------------------------------------------------------------------------------------\n",
            "objective/kl: 1.302072525024414\n",
            "ppo/returns/mean: 0.39998340606689453\n",
            "ppo/policy/advantages_mean: -0.007394184358417988\n",
            "STEP: 2\n",
            "---------------------------------------------------------------------------------------------------\n",
            "objective/kl: 2.2566397190093994\n",
            "ppo/returns/mean: 0.23637691140174866\n",
            "ppo/policy/advantages_mean: 0.03028835728764534\n",
            "STEP: 3\n",
            "---------------------------------------------------------------------------------------------------\n",
            "objective/kl: 3.3771462440490723\n",
            "ppo/returns/mean: 0.1740179806947708\n",
            "ppo/policy/advantages_mean: 0.006248618010431528\n",
            "STEP: 4\n",
            "---------------------------------------------------------------------------------------------------\n",
            "objective/kl: 4.743429183959961\n",
            "ppo/returns/mean: 0.047098226845264435\n",
            "ppo/policy/advantages_mean: 0.02830910123884678\n",
            "STEP: 5\n",
            "---------------------------------------------------------------------------------------------------\n",
            "objective/kl: 4.164358615875244\n",
            "ppo/returns/mean: 0.031082196161150932\n",
            "ppo/policy/advantages_mean: -0.00024298951029777527\n",
            "STEP: 6\n",
            "---------------------------------------------------------------------------------------------------\n",
            "objective/kl: 4.944843292236328\n",
            "ppo/returns/mean: -0.03381596878170967\n",
            "ppo/policy/advantages_mean: -0.012482048012316227\n",
            "STEP: 7\n",
            "---------------------------------------------------------------------------------------------------\n",
            "objective/kl: 3.6851682662963867\n",
            "ppo/returns/mean: -0.028302107006311417\n",
            "ppo/policy/advantages_mean: -0.0021990567911416292\n",
            "STEP: 8\n",
            "---------------------------------------------------------------------------------------------------\n",
            "objective/kl: 4.764088153839111\n",
            "ppo/returns/mean: -0.2261285036802292\n",
            "ppo/policy/advantages_mean: 0.04488302022218704\n",
            "STEP: 9\n",
            "---------------------------------------------------------------------------------------------------\n",
            "objective/kl: 3.3169455528259277\n",
            "ppo/returns/mean: -0.05769351124763489\n",
            "ppo/policy/advantages_mean: 0.0005788858979940414\n",
            "STEP: 10\n",
            "---------------------------------------------------------------------------------------------------\n",
            "objective/kl: 3.063626289367676\n",
            "ppo/returns/mean: -0.0671464130282402\n",
            "ppo/policy/advantages_mean: 0.033140670508146286\n",
            "STEP: 11\n",
            "---------------------------------------------------------------------------------------------------\n",
            "objective/kl: 2.4393861293792725\n",
            "ppo/returns/mean: -0.05307130888104439\n",
            "ppo/policy/advantages_mean: -0.04018360376358032\n",
            "STEP: 12\n",
            "---------------------------------------------------------------------------------------------------\n",
            "objective/kl: 3.5877819061279297\n",
            "ppo/returns/mean: -0.08061088621616364\n",
            "ppo/policy/advantages_mean: 0.01873578503727913\n",
            "STEP: 13\n",
            "---------------------------------------------------------------------------------------------------\n",
            "objective/kl: 3.919843912124634\n",
            "ppo/returns/mean: -0.06214718893170357\n",
            "ppo/policy/advantages_mean: 0.017376145347952843\n",
            "STEP: 14\n",
            "---------------------------------------------------------------------------------------------------\n",
            "objective/kl: 3.6515116691589355\n",
            "ppo/returns/mean: -0.06643285602331161\n",
            "ppo/policy/advantages_mean: -0.00022214018099475652\n",
            "STEP: 15\n",
            "---------------------------------------------------------------------------------------------------\n",
            "objective/kl: 3.40012788772583\n",
            "ppo/returns/mean: 0.018793465569615364\n",
            "ppo/policy/advantages_mean: 0.007460984867066145\n",
            "STEP: 16\n",
            "---------------------------------------------------------------------------------------------------\n",
            "objective/kl: 4.4371795654296875\n",
            "ppo/returns/mean: -0.012952141463756561\n",
            "ppo/policy/advantages_mean: -0.030835896730422974\n",
            "STEP: 17\n",
            "---------------------------------------------------------------------------------------------------\n",
            "objective/kl: 2.988795042037964\n",
            "ppo/returns/mean: -0.01367118488997221\n",
            "ppo/policy/advantages_mean: 0.03999213129281998\n",
            "STEP: 18\n",
            "---------------------------------------------------------------------------------------------------\n",
            "objective/kl: 3.294877052307129\n",
            "ppo/returns/mean: -0.03879000246524811\n",
            "ppo/policy/advantages_mean: -0.013289052061736584\n",
            "STEP: 19\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "APIError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-dfa417f09ad2>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_summaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;31m# score = float(score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mreward_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-340b1ce1fe31>\u001b[0m in \u001b[0;36mscore_summaries\u001b[0;34m(full_text, summarized_text)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m### SUMMARIZED TEXT: \\n {summarized_text}\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0mtemperature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    153\u001b[0m         )\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         )\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m             return (\n\u001b[0;32m--> 710\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    711\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    776\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             )\n",
            "\u001b[0;31mAPIError\u001b[0m: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Sat, 30 Sep 2023 14:01:13 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '80ecf07faca72760-SEA', 'alt-svc': 'h3=\":443\"; ma=86400'}"
          ]
        }
      ],
      "source": [
        "objective_kl    = []\n",
        "returns_mean    = []\n",
        "advantages_mean = []\n",
        "\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for step, batch in enumerate(ppo_trainer.dataloader):\n",
        "\n",
        "    if step >= max_ppo_steps: # Break when we reach max_steps.\n",
        "        break\n",
        "\n",
        "\n",
        "    prompts = [policy_tokenizer.decode(tok) for tok in batch['input_ids']][0]\n",
        "    prompt_tensors = batch[\"input_ids\"]\n",
        "    # print(batch['response'])\n",
        "    # if step==0: break\n",
        "\n",
        "    if isinstance(prompt_tensors, list) and all(isinstance(item, list) for item in prompt_tensors): # HACK!!! Check if original_prompt_tensors is a list of lists\n",
        "        lengths = [len(seq) for seq in prompt_tensors] # Verify if sequences have fixed or variable length\n",
        "        unique_lengths = set(lengths)\n",
        "\n",
        "        if len(unique_lengths) > 1: # If sequences have variable lengths, pad them\n",
        "            max_length = max(unique_lengths)\n",
        "            original_prompt_tensors = [seq + [0] * (max_length - len(seq)) for seq in prompt_tensors]  # padding with zeros\n",
        "\n",
        "        prompt_tensors = [torch.tensor(seq).to(device) for seq in prompt_tensors] # Convert original_prompt_tensors to individual tensors\n",
        "\n",
        "    summary_tensors = []\n",
        "\n",
        "    for prompt_tensor in prompt_tensors:\n",
        "        prompt_tensor = torch.tensor(prompt_tensor).to(device)\n",
        "        max_new_tokens = output_length_sampler()\n",
        "        generation_kwargs[\"max_new_tokens\"] = max_new_tokens\n",
        "        summary = ppo_trainer.generate(prompt_tensor, **generation_kwargs)\n",
        "        summary_tensors.append(summary.squeeze()[-max_new_tokens:])\n",
        "\n",
        "    batch[\"response\"] = [policy_tokenizer.decode(r.squeeze()) for r in summary_tensors]\n",
        "\n",
        "    response = batch[\"response\"]\n",
        "\n",
        "    reward_tensors = []\n",
        "\n",
        "    for prompt, summary in zip(prompts, response):\n",
        "        score = score_summaries(prompt, response)\n",
        "        # score = float(score)\n",
        "        reward_tensors.append(torch.tensor(score))\n",
        "\n",
        "    stats = ppo_trainer.step(prompt_tensors, summary_tensors, reward_tensors)\n",
        "    ppo_trainer.log_stats(stats, batch, reward_tensors)\n",
        "\n",
        "    print(f'objective/kl: {stats[\"objective/kl\"]}') # Measures how different the policy's action distribution after the update is from the action distribution before the update. PPO tries to make these changes very small to avoid sudden changes.\n",
        "    print(f'ppo/returns/mean: {stats[\"ppo/returns/mean\"]}') # This is the average return achieved by the agent. Higher is better.\n",
        "    print(f'ppo/policy/advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}') # Measures how much better an action is than the average action at a given state.\n",
        "    print(f'STEP: {step}')\n",
        "\n",
        "    objective_kl.append(stats[\"objective/kl\"])\n",
        "    returns_mean.append(stats[\"ppo/returns/mean\"])\n",
        "    advantages_mean.append(stats[\"ppo/policy/advantages_mean\"])\n",
        "\n",
        "    print('-'.join('' for x in range(100)))\n",
        "\n",
        "end = time.time()\n",
        "print(f'TIME: {end - start}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpFm4nQmtOCb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Data for plotting\n",
        "t = np.array(returns_mean)\n",
        "s = range(len(returns_mean))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(s, t)\n",
        "\n",
        "ax.set(xlabel='episodes', ylabel='mean return',\n",
        "       title='Policy optimization')\n",
        "# ax.grid()\n",
        "\n",
        "fig.savefig(\"test.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Yw12zuaIkTS"
      },
      "source": [
        "## Saving the Model and Tokenizer\n",
        "\n",
        "After the fine-tuning process, it's crucial to save the model's weights and the tokenizer's configuration for future use, whether it's for inference, further training, or sharing with the community.\n",
        "\n",
        "### 1. Saving the Model\n",
        "\n",
        "To preserve the state of your model post-training, use the `save_pretrained` method:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6H_cP0eeaWV"
      },
      "outputs": [],
      "source": [
        "ppo_trainer.model.push_to_hub('PanoEvJ/T5_summarization_RLAIF', token='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')\n",
        "policy_tokenizer.push_to_hub('PanoEvJ/T5_summarization_RLAIF', token='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')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4ZO9z-_IiGb"
      },
      "outputs": [],
      "source": [
        "objective_kl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5U5GDmwIvDk"
      },
      "outputs": [],
      "source": [
        "returns_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyEL-Y3EIzxv"
      },
      "outputs": [],
      "source": [
        "advantages_mean"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8587deb801b347ed98ae19c4ad16369a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46ab0db4b0de4fbf9eb5799bef9642c1",
              "IPY_MODEL_6fb10ae4ae6140dc92e104e4d837cfed",
              "IPY_MODEL_ea3903adc01a495aae5435ca07437577"
            ],
            "layout": "IPY_MODEL_044729feea174714a3b3497701945e99"
          }
        },
        "46ab0db4b0de4fbf9eb5799bef9642c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d39bfcd50ede48ed99bc41c7c8e603ff",
            "placeholder": "​",
            "style": "IPY_MODEL_07b0f2011f5649d486e383f45def31e3",
            "value": "Map: 100%"
          }
        },
        "6fb10ae4ae6140dc92e104e4d837cfed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5449da55e8a140ccac87fd5d29bac9f1",
            "max": 1600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5926eca80cfd43b2aaf346f029a282b9",
            "value": 1600
          }
        },
        "ea3903adc01a495aae5435ca07437577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af2a710ac70a4716b42a1aab62adc7a9",
            "placeholder": "​",
            "style": "IPY_MODEL_5fed99536689424da956065fbae30bce",
            "value": " 1600/1600 [00:03&lt;00:00, 492.42 examples/s]"
          }
        },
        "044729feea174714a3b3497701945e99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d39bfcd50ede48ed99bc41c7c8e603ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07b0f2011f5649d486e383f45def31e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5449da55e8a140ccac87fd5d29bac9f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5926eca80cfd43b2aaf346f029a282b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af2a710ac70a4716b42a1aab62adc7a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fed99536689424da956065fbae30bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c67d4971ca6540389ff0cb4a980f8532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18de551832c54fcda6d13077d9a2de2d",
              "IPY_MODEL_fec60bfc971c4b56bb101f24faf3509e",
              "IPY_MODEL_fe6bfa77fb8d43dba2cb80a82f2d98e9"
            ],
            "layout": "IPY_MODEL_e3d08ac14f0b413daeaac5c5de257a79"
          }
        },
        "18de551832c54fcda6d13077d9a2de2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_476e4b3e74c046e9bde09ae237624dc5",
            "placeholder": "​",
            "style": "IPY_MODEL_7ef39464cc5a482f90d1adf398ac8dcc",
            "value": "Map: 100%"
          }
        },
        "fec60bfc971c4b56bb101f24faf3509e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_853eecbaa8be4c79a6a48c7dd85f18ae",
            "max": 400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f13c0840a4b48a5a57e5f4a066a16c4",
            "value": 400
          }
        },
        "fe6bfa77fb8d43dba2cb80a82f2d98e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c4573002747418cb78fa1ace8d35786",
            "placeholder": "​",
            "style": "IPY_MODEL_6e3428ab10b3424d803140e1ab080965",
            "value": " 400/400 [00:00&lt;00:00, 506.02 examples/s]"
          }
        },
        "e3d08ac14f0b413daeaac5c5de257a79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "476e4b3e74c046e9bde09ae237624dc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ef39464cc5a482f90d1adf398ac8dcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "853eecbaa8be4c79a6a48c7dd85f18ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f13c0840a4b48a5a57e5f4a066a16c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c4573002747418cb78fa1ace8d35786": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e3428ab10b3424d803140e1ab080965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}